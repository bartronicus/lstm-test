{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TCN2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMmsbf6AA71DECqLlQATMCA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bartronicus/lstm-test/blob/master/TCN2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNTsoqIODqL1"
      },
      "source": [
        "from multiprocessing import Pool\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import files, drive\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import datetime\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSP8qwHkDklE",
        "outputId": "76343316-f6ed-455c-ae52-14f383c872cc"
      },
      "source": [
        "import sys\n",
        "!git clone https://github.com/locuslab/TCN.git\n",
        "p = '/content/TCN/TCN/'\n",
        "if p not in sys.path:\n",
        "  sys.path.insert(0, p)\n",
        "print(sys.path)\n",
        "from tcn import TemporalConvNet"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'TCN'...\n",
            "remote: Enumerating objects: 143, done.\u001b[K\n",
            "remote: Total 143 (delta 0), reused 0 (delta 0), pack-reused 143\u001b[K\n",
            "Receiving objects: 100% (143/143), 16.22 MiB | 21.68 MiB/s, done.\n",
            "Resolving deltas: 100% (61/61), done.\n",
            "['/content/TCN/TCN/', '', '/content', '/env/python', '/usr/lib/python37.zip', '/usr/lib/python3.7', '/usr/lib/python3.7/lib-dynload', '/usr/local/lib/python3.7/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.7/dist-packages/IPython/extensions', '/root/.ipython']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys6M3vf1DtrP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3149f47-f7f5-40f2-984b-d77303e431bd"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "\n",
        "raw = 0\n",
        "for i,f in enumerate(os.listdir('/content/gdrive/MyDrive/klines')):\n",
        "  # if i > 12: \n",
        "  #   continue\n",
        "  path = '/content/gdrive/MyDrive/klines/' + f\n",
        "  csv = pd.read_csv(path)\n",
        "  if type(raw) == int:\n",
        "    raw = csv\n",
        "  else:\n",
        "    raw = raw.append(csv)\n",
        "\n",
        "# raw = pd.read_csv('/content/gdrive/MyDrive/klines/BTCUSDT-klines.csv')\n",
        "# raw = raw.append(pd.read_csv('/content/gdrive/MyDrive/klines/ETHUSDT-klines.csv'))\n",
        "# raw = raw.append(pd.read_csv('/content/gdrive/MyDrive/klines/DOGEUSDT-klines.csv'))\n",
        "# btc.info()\n",
        "# raw.info()\n",
        "# raw.info()\n",
        "raw.sort_values(by=['symbol', 'openTime'],inplace=True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0r3q7sT7V5zz"
      },
      "source": [
        "raw.head()\n",
        "# test = raw\n",
        "# # test['closeTime'] = pd.to_datetime(test['closeTime'], unit='ms')\n",
        "# test.head()\n",
        "# # print(test['closeTime'].max())\n",
        "# test['closeTime'].min()\n",
        "# test.info()\n",
        "raw.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CqZKasYEhq2",
        "outputId": "26ede5e6-8755-46f4-e329-84d68dde4907"
      },
      "source": [
        "cols = ['open', 'high', 'low', 'close','volume','quoteVolume','numberOfTrades','takerBuyBaseVolume','takerBuyQuoteVolume']\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v3TdOuaErN2"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = raw.dropna()\n",
        "minutes = 60\n",
        "data = raw.dropna()\n",
        "data.index = pd.to_datetime(data['closeTime'], unit=\"ms\")\n",
        "\n",
        "data['y'] = data['close'].shift(-minutes)\n",
        "# when we shift the closing price data from some coin may get assigned to another coin\n",
        "# just drop wherever this happens\n",
        "data['symbol_check'] = data['symbol'].shift(-minutes)\n",
        "data['close_time_test'] =  data['closeTime'].shift(-minutes)\n",
        "# check that the y value is actually from [minutes] in the future\n",
        "data['diff'] = data['close_time_test'] - data['closeTime']\n",
        "data = data[data['diff'] == 60000*minutes]\n",
        "\n",
        "data.reset_index(drop = True, inplace=True)\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "data = data[data['symbol'] == data['symbol_check']]\n",
        "\n",
        "# # tolerate a 2 minute gap\n",
        "data['diff'] = data['closeTime'].shift(-1) - data['closeTime']\n",
        "data = data[data['diff'] < (60000 * 2)]\n",
        "data.dropna(inplace=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqJqTA4DHTUF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7d19853-2227-4337-87ce-9a9a55a3849c"
      },
      "source": [
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "series_len = 1000\n",
        "\n",
        "data['series'] = (data['closeTime'].shift(-1) - data['closeTime']) > 60000 * 2\n",
        "data['series'] = data['series'] + (data['symbol'] != data['symbol_check'])\n",
        "data['series'] = data['series'] * data.index\n",
        "data['series'] = data.groupby(data['series']).ngroup()\n",
        "data['series'] = data['series'].replace(0,np.NaN)\n",
        "data['series'][0] = 0\n",
        "data['series'].unique()\n",
        "data['series'] = data['series'].fillna(method='ffill')\n",
        "data['series'] = data['series'].shift(1)\n",
        "data = data.dropna()\n",
        "data['series_index'] = data.groupby('series').cumcount()\n",
        "\n",
        "# DROP SERIES BELOW MINIMUM LENGTH \n",
        "series_len_df = data.groupby(data['series']).size().reset_index(name='series_len')\n",
        "data = data.merge(series_len_df, on='series', how='left')\n",
        "data = data[data['series_len'] >= series_len]\n",
        "data = data.reset_index()\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/computation/expressions.py:204: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
            "  f\"evaluating in Python space because the {repr(op_str)} \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfzYCxcnpnxA"
      },
      "source": [
        "losses = []\n",
        "\n",
        "df = pd.DataFrame(columns = data.columns)\n",
        "\n",
        "for series in data.series.unique():\n",
        "  series = data[data['series'] == series]\n",
        "  scaler = MinMaxScaler()\n",
        "  scaler.fit(data[[*cols,'y']])\n",
        "  series[[*cols,'y']] = scaler.fit_transform(series[[*cols,'y']])\n",
        "  df = df.append(series)  \n",
        "\n",
        "  # benchmark\n",
        "  # what if we just used the last price to predict the next?\n",
        "  loss_fn = nn.MSELoss()\n",
        "  close = torch.tensor(series['close'].to_numpy())\n",
        "  y = torch.tensor(series['y'].to_numpy())\n",
        "  loss = loss_fn(close,y)\n",
        "  losses.append(loss.item())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyXSLKWLNxYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f163eb98-68f5-406e-a245-0dfb382a3727"
      },
      "source": [
        "del data\n",
        "print(np.asarray(losses).sum() / len(losses))\n",
        "print('\\n')\n",
        "losses"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.00020580091812136676\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0012901556831559904,\n",
              " 0.00018105799022889252,\n",
              " 0.000530716150873572,\n",
              " 7.692526895257364e-05,\n",
              " 8.163464005221232e-05,\n",
              " 0.0001639402783458955,\n",
              " 5.351250869534212e-05,\n",
              " 2.4835866963275576e-05,\n",
              " 0.00013283638288111635,\n",
              " 3.603844284608843e-05,\n",
              " 0.00018509666633841808,\n",
              " 4.990471745535988e-05,\n",
              " 6.615631225537079e-05,\n",
              " 2.8683432180140504e-05,\n",
              " 0.0001582282926258355,\n",
              " 9.069086067724878e-05,\n",
              " 0.00010205045778532901,\n",
              " 4.6304711270886524e-05,\n",
              " 4.014545304909859e-05,\n",
              " 0.00015473836386807155,\n",
              " 0.0003081559719865387,\n",
              " 5.191601014388456e-06,\n",
              " 2.1217897427267217e-06,\n",
              " 0.00034641535168244964,\n",
              " 4.9037176146974195e-05,\n",
              " 0.00022225596274657377,\n",
              " 5.7813290565120545e-05,\n",
              " 9.290684708018316e-05,\n",
              " 0.00011738237246334708,\n",
              " 0.00016464194319644316,\n",
              " 8.274838904520969e-05,\n",
              " 0.0016433062037130627]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qg7NuvYaDx9c"
      },
      "source": [
        "class TCN(nn.Module):\n",
        "    def __init__(self, input_size, output_size, num_channels, kernel_size, dropout):\n",
        "        super(TCN, self).__init__()\n",
        "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout=dropout)\n",
        "        self.linear = nn.Linear(num_channels[-1], num_channels[-1])\n",
        "        self.linear_out = nn.Linear(num_channels[-1], output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.tcn(x.transpose(1, 2)).transpose(1, 2)\n",
        "        output = self.linear(output)\n",
        "        output = self.relu(output)\n",
        "        # output = torch.squeeze(output)\n",
        "        output = self.linear_out(output)\n",
        "        output = torch.sum(output,1)\n",
        "        output = torch.squeeze(output)\n",
        "        # print(output,output.shape)\n",
        "        return output\n",
        "\n",
        "        # output = self.linear(output).double()\n",
        "        # output = self.sig(output)\n",
        "        # output = torch.sum(output)\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0VIJvzusFkY"
      },
      "source": [
        "import random\n",
        "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
        "from itertools import chain, islice, cycle, filterfalse\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "class TimeSeries(IterableDataset):\n",
        "  \n",
        "  def __init__(self, data_list):\n",
        "    self.data_list = data_list\n",
        "  \n",
        "  def process_data(self, df):\n",
        "    valid_rows = df[df['series_index'] >= series_len]\n",
        "    data_cols = df[cols]\n",
        "    for i in valid_rows.index:\n",
        "      x = data_cols.iloc[i-series_len:i].to_numpy()\n",
        "      yield {\n",
        "          \"x\": x,\n",
        "          \"y\": df['y'].at[i]\n",
        "      }\n",
        "  \n",
        "  def get_stream(self, data_list):\n",
        "    return chain.from_iterable(map(self.process_data,cycle(data_list)))\n",
        "  \n",
        "  def __iter__(self):\n",
        "    return self.get_stream(self.data_list)\n",
        "\n",
        "def get_df_series(series_int):\n",
        "  d = df[df['series'] == series_int]\n",
        "  return d.reset_index()\n",
        "\n",
        "series_list = list(map(get_df_series, df.series.unique()))\n",
        "random.Random(0).shuffle(series_list)\n",
        "\n",
        "train_len = int(len(series_list)*.8)\n",
        "test_len = int(len(series_list)*.2)\n",
        "\n",
        "train_data = TimeSeries(series_list[:train_len])\n",
        "test_data = TimeSeries(series_list[train_len:])\n",
        "\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=test_len)\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yq_KmpgRAkcz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_AV8fPfD3e8"
      },
      "source": [
        "def evaluate():\n",
        "  model.eval()  \n",
        "  eval_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for data in islice(test_loader,1):\n",
        "      x = data['x'].to(device)\n",
        "      y = data['y'].to(device)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      output = model(x)\n",
        "      loss = loss_fn(y, output)\n",
        "      eval_loss = loss.item()\n",
        "      writer.add_scalar(\"Eval\" + ' loss', eval_loss, ep)\n",
        "      # eval_loss = total_loss / count\n",
        "      print(\"Eval\" + \" loss: {:.5f}\".format(eval_loss))\n",
        "      return eval_loss\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gN5YjFfGD41w"
      },
      "source": [
        "\n",
        "def train(ep):\n",
        "  valid_rows = int(len(df[df['series_index'] >= series_len])/batch_size)\n",
        "  gen = tqdm(islice(train_loader, valid_rows),position=0,total=valid_rows)\n",
        "  model.train()\n",
        "  total_loss = 0\n",
        "  count = 0\n",
        "  \n",
        "  for batch in gen:\n",
        "    x = batch['x'].to(device)\n",
        "    if x.shape[0] != batch_size:\n",
        "      print(x.shape)\n",
        "    y = batch['y'].to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(x)\n",
        "    loss = loss_fn(y, output)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    total_loss += loss.item()\n",
        "    count += 1\n",
        "\n",
        "  if count > 0:\n",
        "    curr_loss = total_loss / count\n",
        "    writer.add_scalar('training loss', curr_loss, ep)\n",
        "    print(\"\\nEpoch \",ep,\"| lr |\", params[\"lr\"], \"loss\", curr_loss,\"\\n\")\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0LvWEmuMvno"
      },
      "source": [
        "\n",
        "\n",
        "*   adding a channel from 6x6+1 to 7x6+1 was good\n",
        "*   improved by jumping up to 60,40,40,30,20,10,1 \n",
        "      somehow, 50,40... and 60,50... were sign. worse\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_41UrhaD-6n"
      },
      "source": [
        "title = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "writer = SummaryWriter('/runs/' + title)\n",
        "best_tloss = 1e8\n",
        "model_name = \"btc.pt\"\n",
        "epochs = 100\n",
        "torch.manual_seed(0)\n",
        "random.seed(0)\n",
        "\n",
        "params = {\n",
        "  # 'num_channels': [60,40,30,20,10,4,2,1],\n",
        "  # 'num_channels': [10,20,30,40,60],\n",
        "  'num_channels':[1,2,3,4,6,12,24],\n",
        "  'kernel_size': 3,\n",
        "  'dropout': 0.75,\n",
        "  'batch_size': 64,\n",
        "  'lr': 1e-3\n",
        "}\n",
        "\n",
        "model = TCN(len(cols), 1, params['num_channels'], params['kernel_size'], dropout = params['dropout'])\n",
        "model = model.to(dtype=torch.float64)\n",
        "model = model.to(device)\n",
        "loss_fn = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=params['lr'])\n",
        "\n",
        "for ep in range(1, epochs+1):\n",
        "    print('\\n\\nSTARTING EPOCH',ep,'\\n\\n')\n",
        "    train(ep)\n",
        "    tloss = evaluate()\n",
        "    if tloss < best_tloss:\n",
        "        with open(model_name, \"wb\") as f:\n",
        "            torch.save(model, f)\n",
        "            print(\"Saved model!\")\n",
        "        best_tloss = tloss\n",
        "    # if ep > 10 and tloss > best_tloss: \n",
        "    #   params['lr'] /= 10\n",
        "    #   for param_group in optimizer.param_groups:\n",
        "    #     param_group['lr'] = params['lr']\n",
        "\n",
        "\n",
        "writer.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfXgzYUPEDhW"
      },
      "source": [
        "# %load_ext tensorboard\n",
        "%tensorboard --logdir /runs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpUcdpnS7S5"
      },
      "source": [
        "from tempfile import TemporaryFile\n",
        "outfile = TemporaryFile()\n",
        "\n",
        "p = '/content/gdrive/MyDrive/binance_time_series.csv'\n",
        "\n",
        "\n",
        "# valid_rows = df[df['series_index'] >= series_len]\n",
        "\n",
        "# with open(p, 'w') as csvfile:\n",
        "#   for i in tqdm(valid_rows.index, position=0):\n",
        "#     x = df[cols].iloc[i-series_len:i].to_numpy()\n",
        "#     x = x.ravel()\n",
        "#     y = df.at[i,'y']\n",
        "        \n",
        "#     writ = csv.writer(csvfile, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
        "#     writ.writerow([*x,y]) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKGrgNUclohq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc804f8c-8c6d-4316-b359-48b7cbe148a7"
      },
      "source": [
        "import h5py\n",
        "import numpy as np\n",
        "\n",
        "valid_rows = df[df['series_index'] >= series_len]\n",
        "# p = '/content/gdrive/MyDrive/binance_time_series.hdf5'\n",
        "# f = h5py.File(p,  \"w\")\n",
        "\n",
        "\n",
        "# dset = f.create_dataset('dataset', (len(valid_rows),2))\n",
        "\n",
        "# valid_rows = df[df['series_index'] >= series_len]\n",
        "# x_set = f.create_dataset('xset', (len(valid_rows),series_len,len(cols)), dtype=np.float64)\n",
        "# y_set = f.create_dataset('yset', (len(valid_rows),), dtype=np.float64)\n",
        "\n",
        "m = 0\n",
        "\n",
        "def enumerate2(xs, start=0, step=1):\n",
        "    for x in xs:\n",
        "        yield (start, x)\n",
        "        start += step\n",
        "\n",
        "for i,s in tqdm(enumerate(df.series.unique()),position=0):\n",
        "  print('dis is a new series',i,'/',len(df.series.unique()))\n",
        "  d = df[df['series'] == s]    \n",
        "  d.reset_index(inplace=True)\n",
        "  data_cols = d[cols]\n",
        "\n",
        "  for j in tqdm(d.index,position=0):\n",
        "    l = j + series_len\n",
        "    x = data_cols.iloc[j:l].to_numpy()\n",
        "\n",
        "    if x.sum() == 0:\n",
        "      print('IT\\'S BROKEN HERE WTF',i,j)\n",
        "      continue\n",
        "\n",
        "    if x.shape[0] < series_len:\n",
        "      continue\n",
        "\n",
        "    try: \n",
        "      y = d['y'][l]\n",
        "      x_set[m] = x\n",
        "      y_set[m] = y\n",
        "\n",
        "      m += 1\n",
        "    except:\n",
        "      continue\n"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  1%|          | 162/24797 [00:00<00:15, 1619.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 0 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 24797/24797 [00:16<00:00, 1474.41it/s]\n",
            "  0%|          | 142/44419 [00:00<00:31, 1415.13it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 1 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44419/44419 [00:29<00:00, 1489.28it/s]\n",
            "  0%|          | 141/44409 [00:00<00:31, 1403.90it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 2 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44409/44409 [00:37<00:00, 1187.33it/s]\n",
            "  0%|          | 160/44447 [00:00<00:27, 1585.74it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 3 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44447/44447 [00:40<00:00, 1102.64it/s]\n",
            "  0%|          | 133/44441 [00:00<00:33, 1325.91it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 4 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44441/44441 [00:42<00:00, 1052.57it/s]\n",
            "  0%|          | 146/44435 [00:00<00:30, 1454.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 5 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44435/44435 [00:36<00:00, 1221.08it/s]\n",
            "  0%|          | 133/44433 [00:00<00:33, 1315.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 6 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44433/44433 [00:40<00:00, 1105.17it/s]\n",
            "  0%|          | 143/44402 [00:00<00:31, 1421.05it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 7 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44402/44402 [00:42<00:00, 1044.46it/s]\n",
            "  0%|          | 148/44427 [00:00<00:30, 1472.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 8 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44427/44427 [00:36<00:00, 1225.18it/s]\n",
            "  0%|          | 167/44447 [00:00<00:26, 1669.26it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 9 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44447/44447 [00:36<00:00, 1203.01it/s]\n",
            "  0%|          | 156/44399 [00:00<00:28, 1558.65it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 10 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44399/44399 [00:42<00:00, 1052.99it/s]\n",
            "  0%|          | 140/44452 [00:00<00:31, 1394.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 11 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44452/44452 [00:40<00:00, 1109.04it/s]\n",
            "  0%|          | 141/44450 [00:00<00:31, 1402.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 12 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44450/44450 [00:37<00:00, 1182.39it/s]\n",
            "  0%|          | 169/44381 [00:00<00:26, 1684.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 13 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44381/44381 [00:35<00:00, 1236.11it/s]\n",
            "  0%|          | 137/44449 [00:00<00:32, 1362.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 14 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44449/44449 [00:40<00:00, 1095.83it/s]\n",
            "  0%|          | 142/44454 [00:00<00:31, 1418.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 15 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44454/44454 [00:41<00:00, 1063.92it/s]\n",
            "  0%|          | 136/44384 [00:00<00:32, 1358.92it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 16 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44384/44384 [00:37<00:00, 1185.29it/s]\n",
            "  0%|          | 138/44465 [00:00<00:32, 1375.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 17 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44465/44465 [00:41<00:00, 1067.63it/s]\n",
            "  0%|          | 134/44412 [00:00<00:33, 1329.59it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 18 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44412/44412 [00:37<00:00, 1185.59it/s]\n",
            "  0%|          | 159/44440 [00:00<00:27, 1584.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 19 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44440/44440 [00:36<00:00, 1211.13it/s]\n",
            "  0%|          | 163/44406 [00:00<00:27, 1624.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 20 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44406/44406 [00:42<00:00, 1052.93it/s]\n",
            "  0%|          | 124/44433 [00:00<00:36, 1218.73it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 21 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44433/44433 [00:39<00:00, 1132.60it/s]\n",
            "  0%|          | 136/44449 [00:00<00:32, 1355.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 22 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44449/44449 [00:38<00:00, 1142.80it/s]\n",
            "  0%|          | 130/44414 [00:00<00:34, 1294.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 23 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44414/44414 [00:38<00:00, 1153.02it/s]\n",
            "  0%|          | 150/44433 [00:00<00:29, 1496.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 24 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44433/44433 [00:40<00:00, 1094.08it/s]\n",
            "  0%|          | 153/44428 [00:00<00:28, 1529.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 25 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44428/44428 [00:38<00:00, 1146.32it/s]\n",
            "  0%|          | 156/44456 [00:00<00:28, 1557.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 26 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44456/44456 [00:40<00:00, 1106.20it/s]\n",
            "  0%|          | 136/44411 [00:00<00:32, 1353.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 27 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44411/44411 [00:38<00:00, 1165.16it/s]\n",
            "  0%|          | 134/44453 [00:00<00:33, 1336.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 28 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44453/44453 [00:40<00:00, 1101.23it/s]\n",
            "  0%|          | 142/44393 [00:00<00:31, 1414.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 29 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44393/44393 [00:37<00:00, 1197.33it/s]\n",
            "  0%|          | 127/44453 [00:00<00:35, 1262.72it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 30 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 44453/44453 [00:41<00:00, 1082.76it/s]\n",
            "  1%|          | 122/19648 [00:00<00:16, 1203.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dis is a new series 31 / 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 19648/19648 [00:14<00:00, 1322.99it/s]\n",
            "32it [20:03, 37.59s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZwBSDIkVXwD",
        "outputId": "860788c8-bf6d-4fc8-9052-cf5ddf4e0f6a"
      },
      "source": [
        "x_set[0]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.07360252, 0.05635311, 0.07246269, ..., 0.01220069, 0.01358676,\n",
              "        0.00971611],\n",
              "       [0.0766594 , 0.05932382, 0.077     , ..., 0.02042588, 0.02728824,\n",
              "        0.01957959],\n",
              "       [0.07757943, 0.0565793 , 0.07525373, ..., 0.01325169, 0.01535505,\n",
              "        0.01099257],\n",
              "       ...,\n",
              "       [0.09394708, 0.07482583, 0.09447761, ..., 0.00927618, 0.01367359,\n",
              "        0.00993443],\n",
              "       [0.09446646, 0.07390596, 0.09331343, ..., 0.00840797, 0.01048039,\n",
              "        0.00761041],\n",
              "       [0.09287866, 0.07560998, 0.09352239, ..., 0.01325169, 0.04768719,\n",
              "        0.03465572]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5NEqXlJ_mAd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}